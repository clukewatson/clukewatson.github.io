[
  {
    "objectID": "research/nyc-monopoly/index.html#pdf-links",
    "href": "research/nyc-monopoly/index.html#pdf-links",
    "title": "Is the Rent Too High? Land Ownership and Monopoly Power",
    "section": "PDF links",
    "text": "PDF links\n\nPaper (March 2021)"
  },
  {
    "objectID": "research/nyc-monopoly/index.html#abstract",
    "href": "research/nyc-monopoly/index.html#abstract",
    "title": "Is the Rent Too High? Land Ownership and Monopoly Power",
    "section": "Abstract",
    "text": "Abstract\nWe investigate the sources, scope, and implications of landowner market power. We show how zoning regulations generate spillovers through increased markups and derive conditions under which restricting landownership concentration reduces rents. Using new building-level data from New York City, we fnd that a 10% increase in ownership concentration in a Census tract is correlated with a 1% increase in rent. Market power is substantial: on average, markups account for nearly a third of rents in Manhattan. Furthermore, pecuniary spillovers between zoning constraints and markups at other buildings are appreciable. Up-zoning that results in 417 additional housing units at zoning-constrained buildings reduces markups on policy-unconstrained units and generates between 5 and 19 additional units through increased competition."
  },
  {
    "objectID": "research/nyc-monopoly/index.html#bibtex-citation",
    "href": "research/nyc-monopoly/index.html#bibtex-citation",
    "title": "Is the Rent Too High? Land Ownership and Monopoly Power",
    "section": "BibTeX citation",
    "text": "BibTeX citation\n@techreport{watson_istherenttoohigh:2021,\n    Author = {Watson, C. Luke and Ziv, Oren},\n    Month = {3},\n    Title = {Is the Rent Too High? Land Ownership and Monopoly Power},\n    Type = {Manuscript},\n    Year = {2021}}"
  },
  {
    "objectID": "research/tax-iv-ge/index.html",
    "href": "research/tax-iv-ge/index.html",
    "title": "Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers",
    "section": "",
    "text": "Paper"
  },
  {
    "objectID": "research/tax-iv-ge/index.html#pdf-links",
    "href": "research/tax-iv-ge/index.html#pdf-links",
    "title": "Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers",
    "section": "",
    "text": "Paper"
  },
  {
    "objectID": "research/tax-iv-ge/index.html#abstract",
    "href": "research/tax-iv-ge/index.html#abstract",
    "title": "Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers",
    "section": "Abstract",
    "text": "Abstract\nZoutman, Gavrilova, & Hopland (Econometrica, 2018) show that by knowing on ‘which side of the market’ an ‘exogenous’ tax is levied one can use a single tax instrument to estimate both a supply and a demand elasticity. This seemingly goes against the intuition that one needs two instruments for two parameters; i.e., a ‘supply’ and a ‘demand’ instrument. I show that the result is only true with partial equilibrium assumptions. Without further assumptions, tax reform induced general equilibrium price spillover effects imply that the tax rates are correlated with the unobserved structural errors. Thus, tax rates on their own are invalid instruments for at least one of the parameters. However, I show that if one can calculate a measure of spillovers, then one can still estimate the two elasticities using one tax reform, but with the spillover measure as an additional instrument."
  },
  {
    "objectID": "research/tax-iv-ge/index.html#authors-notes",
    "href": "research/tax-iv-ge/index.html#authors-notes",
    "title": "Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers",
    "section": "Author’s Notes",
    "text": "Author’s Notes\nI do not expect to revise this paper anytime soon. I submitted it to Economics Letters in Oct 2021, and the paper was rejected with referee reports. The turn-around was quick and I have no complaints about the process.\nI do not wish the paper to be seen as a comment on ZGH 2018; rather, a warning for others looking to follow their advice. One referee claimed that if one includes the other markets’ prices in the structural function (and as expected the first stage), then identification is possible based on results from a 1970s J.Hausman paper. While I trust that referee’s argument is sound, I have not worked this out myself. I do worry that this would not work in finite samples, but then in this case maybe the IV will not work either."
  },
  {
    "objectID": "research/tax-iv-ge/index.html#bibtex-citation",
    "href": "research/tax-iv-ge/index.html#bibtex-citation",
    "title": "Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers",
    "section": "BibTeX citation",
    "text": "BibTeX citation\n@techreport{watson_tax_iv_ge:2021,\n    Author = {C. Luke Watson},\n    Month = {10},\n    Title = {Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers},\n    Type = {Manuscript},\n    Year = {2021}}"
  },
  {
    "objectID": "research/state-eitc/index.html",
    "href": "research/state-eitc/index.html",
    "title": "The Local Effects of State EITC Expansions",
    "section": "",
    "text": "Paper"
  },
  {
    "objectID": "research/state-eitc/index.html#pdf-links",
    "href": "research/state-eitc/index.html#pdf-links",
    "title": "The Local Effects of State EITC Expansions",
    "section": "",
    "text": "Paper"
  },
  {
    "objectID": "research/state-eitc/index.html#abstract",
    "href": "research/state-eitc/index.html#abstract",
    "title": "The Local Effects of State EITC Expansions",
    "section": "Abstract",
    "text": "Abstract\nTwenty eight states spend $4 billion to supplement the federal Earned Income Tax Credit, with several justifying the tax expenditure as a pro-work incentive. Yet no systematic evaluation of these supplements exists. I use state border policy variation to identify state supplements effects. I first document that subsidy rates are greater when a state’s neighbor already has a supplement. Next, I assess whether supplements affect county level EITC take-up, migration, commuting, employment, and earnings. Estimates are sensitive to the estimation design and sample used. While supplements increase benefits to low-income workers, results fail to provide robust evidence of increased economic activity.\nNote: the empirics on this paper are not finalized and should not be cited."
  },
  {
    "objectID": "research/state-eitc/index.html#graph-from-the-paper",
    "href": "research/state-eitc/index.html#graph-from-the-paper",
    "title": "The Local Effects of State EITC Expansions",
    "section": "Graph from the paper",
    "text": "Graph from the paper\n\nTiming and intensity of use\n\n\n\n\n\n\n\nPossible policy coordination"
  },
  {
    "objectID": "research/state-eitc/index.html#bibtex-citation",
    "href": "research/state-eitc/index.html#bibtex-citation",
    "title": "The Local Effects of State EITC Expansions",
    "section": "BibTeX citation",
    "text": "BibTeX citation\n@techreport{watson_state_eitc:2021,\n    Author = {C. Luke Watson},\n    Month = {8},\n    Title = {The Local Effects of State EITC Expansions},\n    Type = {Manuscript},\n    Year = {2021}}"
  },
  {
    "objectID": "research/ge-eitc/index.html#pdf-links",
    "href": "research/ge-eitc/index.html#pdf-links",
    "title": "The General Equilibrium Incidence of the Earned Income Tax Credit",
    "section": "PDF links",
    "text": "PDF links\n\nPaper"
  },
  {
    "objectID": "research/ge-eitc/index.html#abstract",
    "href": "research/ge-eitc/index.html#abstract",
    "title": "The General Equilibrium Incidence of the Earned Income Tax Credit",
    "section": "Abstract",
    "text": "Abstract\nThe Earned Income Tax Credit is a $67 billion tax expenditure that subsidizes 20% of all workers. Yet all prior analysis uses partial equilibrium assumptions on gross wages. I derive the general equilibrium incidence of wage subsidies and quantify the importance of EITC spillovers in three ways. I calculate the GE incidence of the 1993 and 2009 EITC expansions using new elasticity estimates. I contrast the incidence of counterfactual EITC and Welfare expansions. I quantify the effect of equalizing the EITC for workers with and without children. In all cases, I find spillovers are economically meaningful."
  },
  {
    "objectID": "research/ge-eitc/index.html#bibtex-citation",
    "href": "research/ge-eitc/index.html#bibtex-citation",
    "title": "The General Equilibrium Incidence of the Earned Income Tax Credit",
    "section": "BibTeX citation",
    "text": "BibTeX citation\n@techreport{watson_geeitc:2021,\n    Author = {C. Luke Watson},\n    Month = {9},\n    Title = {The General Equilibrium Incidence of the Earned Income Tax Credit},\n    Type = {Manuscript},\n    Year = {2021}}"
  },
  {
    "objectID": "research/tfpp/index.html#pdf-links",
    "href": "research/tfpp/index.html#pdf-links",
    "title": "A Test for Pricing Power in Urban Housing Markets",
    "section": "PDF links",
    "text": "PDF links\n\nPaper (Dec 2023)"
  },
  {
    "objectID": "research/tfpp/index.html#abstract",
    "href": "research/tfpp/index.html#abstract",
    "title": "A Test for Pricing Power in Urban Housing Markets",
    "section": "Abstract",
    "text": "Abstract\nThe presence of pricing power in housing markets alters our understand of the housing supply and land-use policies. It biases estimates of housing production functions and supply elasticities and the results of quantitative spatial models. We test for pricing power in the New York City rental market. We make use of a series of tax policy shifts to conduct complementary difference-in-differences and instrumental variable designs. Holding fixed market prices, we find an increase in a single building’s idiosyncratic costs results in a similar magnitude increase in its rents, consistent with the existence of pricing power and inconsistent with perfect competition."
  },
  {
    "objectID": "research/tfpp/index.html#bibtex-citation",
    "href": "research/tfpp/index.html#bibtex-citation",
    "title": "A Test for Pricing Power in Urban Housing Markets",
    "section": "BibTeX citation",
    "text": "BibTeX citation\n@techreport{watson_testforpricingpower:2023,\n    Author = {Watson, C. Luke and Ziv, Oren},\n    Month = {12},\n    Title = {A Test for Pricing Power in Urban Housing Markets},\n    Type = {Manuscript},\n    Year = {2023}}"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "C. Luke Watson",
    "section": "",
    "text": "A Test for Pricing Power in Urban Housing Markets\n\n\n\n\n\n\n\nRental Markets\n\n\nMarkups\n\n\nMonopoly Power\n\n\nHousing Demand\n\n\n\n\nBuilding demand slope down.\n\n\n\n\n\n\nDec 30, 2023\n\n\nC. Luke Watson, Oren Ziv\n\n\n\n\n\n\n  \n\n\n\n\nEstimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate with General Equilibrium Spillovers\n\n\n\n\n\n\n\nIV\n\n\nTax Incidence\n\n\nSpillovers\n\n\nApplied Econometrics\n\n\n\n\nA note about using tax IVs\n\n\n\n\n\n\nOct 1, 2021\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nThe General Equilibrium Incidence of the Earned Income Tax Credit\n\n\n\n\n\n\n\nEITC\n\n\nLabor Supply\n\n\nLabor Demand\n\n\nIV\n\n\nTax Incidence\n\n\n\n\nMy JMP\n\n\n\n\n\n\nSep 1, 2021\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nThe Local Effects of State EITC Expansions\n\n\n\n\n\n\n\nEITC\n\n\nLabor Supply\n\n\nLabor Demand\n\n\nBorder Discontinuity\n\n\n\n\nChapter 2 of my dissertation\n\n\n\n\n\n\nAug 1, 2021\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nIs the Rent Too High? Land Ownership and Monopoly Power\n\n\n\n\n\n\n\nRental Markets\n\n\nMarkups\n\n\nMonopoly Power\n\n\nHousing Demand\n\n\nZoning\n\n\n\n\nIs it?\n\n\n\n\n\n\nMar 1, 2021\n\n\nC. Luke Watson, Oren Ziv\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-06-09_preference_relations/index.html",
    "href": "posts/2020-06-09_preference_relations/index.html",
    "title": "First year notes on preference relations",
    "section": "",
    "text": "These are notes I wrote on preference relations for first year phd micro: notes01_preferences.pdf. I typed the notes to learn LaTeX and pass the time waiting on getting prelim results. I think they are pretty good. I started a companion set for utility maximization problems, but only got through the math parts without getting to the micro. Maybe I will try to finish it."
  },
  {
    "objectID": "posts/2023-09-17-isolated-places/index.html#what-town-data-do-we-have",
    "href": "posts/2023-09-17-isolated-places/index.html#what-town-data-do-we-have",
    "title": "Isolated Places",
    "section": "What ‘town’ data do we have?",
    "text": "What ‘town’ data do we have?\nThe closest data-product we have for a town is the Cenus Designated Place (CDP). These are “population concentrations” used for statistical purposes. CDPs include large incorporated cities, such as all five boroughs of New York as the New York place, and unincorporated areas, such as Manchester Center, VT. CDPs are not nested within any other geography; i.e., they do not respect counties or ZCTAs.\nFor this project, we want three pieces of data: (1) place demographics, (2) place distance relationships, and (3) place-ZCTA concordances. We want demographics so that we know population of the areas; we want distances so that we can tell who is close to whom; we want concordances so that we can link to firm data. Luckily, we have all three readily available!\nThe NHGIS has collected demographic data for places. The NBER has created distance relationships using geographic interior points. Finally, the Missouri Census Data Center manages GEOCORR to create crosswalks between geography types (within a year, not across); although, I do not use this in this post."
  },
  {
    "objectID": "posts/2023-09-17-isolated-places/index.html#starting-point-allan-collard-wexler",
    "href": "posts/2023-09-17-isolated-places/index.html#starting-point-allan-collard-wexler",
    "title": "Isolated Places",
    "section": "Starting Point: Allan Collard-Wexler",
    "text": "Starting Point: Allan Collard-Wexler\nProf. Allan Collard-Wexler has created an example, which certainly inspired me, for creating an isolated towns dataset. You can find his data here and his tutorial here. I should note two things. First, I cannot replicate his towns. Second, I think there could be some issues with the towns he identifies. I will discuss both points later.\nFor his tutorial:\n\nData : 1990 and 2000 Census Place Gazette file\n\nHe says cuts are based on 1990 population, but the data have 2000 population\nI am not sure how he is geolocating the places\nThe Gazette files have an interior point, but it is possible he calculates his own\nI use the NBER place-distances\n\nA town must have greater than 4000 people\n\nThe tutorial table says 2000, but the minimum population in his data is just above 4000\n\nTo be a neighboring town, a neighbor must have 4000 people\nAny town within 1 mile is not considered a separate town\n\nThus, I will try to replicate his dataset. Point 1 highlights that I do not know how ACW geolocates the places and I use the NBER file. Although, I have done the analysis using population weighted centroids from GEOCORR, and find essentially no differences. Point 4 is actually a little tricky to deal with, so I am going to skip it for now and merge the ACW data with NBER distance data (and population data from NHGIS).\n\n# Load libraries\nlibrary(tidyverse)  \n\n### ACW data\nacw.df &lt;- read_csv(\"lonesome449.csv\")\nacw.df$placefip &lt;- paste0(acw.df$stfips,acw.df$placefip)\n# Note, ACW's lowest pop is 4k not 2k and is for year 2000\nmin(acw.df$population)\n# Also, AK is still in the data \nlength(acw.df$placefip[acw.df$stfips==\"02\"])\n\n### NHGIS data on places in 2000\nplace.00.dat &lt;- read_csv(\"nhgis0058_ds146_2000_place.csv\")\ncolnames(place.00.dat) &lt;- tolower(colnames(place.00.dat))\nplace.00.dat$place.fip &lt;- paste0(place.00.dat$statea,place.00.dat$placea)\nplace.00.dat &lt;- place.00.dat %&gt;%\n  select(year, stusab,statea, place,place.fip,placecc,placedc,arealand,areawatr,intptlat,intplon,\n         fl5001,fnh001,fki001)\n# \ncolnames(place.00.dat) &lt;- c(\"year\", \"stabbr\",\"state.fip\", \n                            \"place.nm\",\"place.fip\",\"placecc\",\"placedc\",\n                            \"place.area.land\",\"place.area.water\",\"place.lat\",\"place.lng\",\n                            \"pop\",\"households\",\"housing.units\")\n\n### NBER data on place distances in 2000\nplace.00.dist &lt;- read_csv(\"sf12000placedistance50miles.csv\")\nplace.00.dist &lt;- place.00.dist %&gt;%\n  mutate(place1 = paste0(state1,place1),\n         place2 = paste0(state2,place2)) %&gt;%\n  select(place1,mi_to_place,place2)\n\n### Drop HI and other areas\n# ACW says it is only continental US, but data has AK\n# NHGIS file only has 50states place DC, so filter out HI\nplace.00.dat &lt;- place.00.dat %&gt;%\n  filter(stabbr!=\"HI\")\n# filter out from NBER file\nplace.00.dist &lt;- place.00.dist %&gt;%\n  mutate(tmp = str_sub(place1,1,2)) %&gt;%\n  filter(tmp %in% unique(place.00.dat$state.fip)) %&gt;%\n  select(-tmp)\n\n### Combine the NHGIS and NBER\n# need to add pop data to the NBER file\n# probably a better way to do this, but creating helper file, delete later\nplace.00.dat.use &lt;- place.00.dat %&gt;%\n  select(place.fip,pop,place.nm)\ncolnames(place.00.dat.use) &lt;- c(\"place1\",\"pop\",\"place.nm\")\n# \nplace.00.df &lt;- full_join(place.00.dat.use,place.00.dist) %&gt;% \n  left_join(place.00.dat.use,by=c(\"place2\"=\"place1\"))\n# add places with minimum distances greater than 50\nplace.00.df$tmp &lt;- is.na(place.00.df$mi_to_place)\nplace.00.df$place2[place.00.df$tmp==T] &lt;- \"9999999\"\nplace.00.df$place.nm.y[place.00.df$tmp==T] &lt;- \"none\"\nplace.00.df$pop.y[place.00.df$tmp==T] &lt;- 0\nplace.00.df$mi_to_place[place.00.df$tmp==T] &lt;- 999\nplace.00.df$tmp &lt;- NULL\n\nrm(place.00.dat.use)\ngc()\n\n#### Combine Dist with ACW\nacw.dist &lt;- acw.df %&gt;%\n  left_join(place.00.df, by=c(\"placefip\"=\"place1\")) %&gt;%\n  select(-c(class,stfips,nbr30,nbr40,autoroute))\n# how many of the places have neighbors with pop&gt;4000 within (5,15) miles\n# note: use (5,15) since there could be some error in the distances from NBER and ACW\nlength(unique(acw.dist$placefip[acw.dist$mi_to_place&lt;15 \n                                & acw.dist$mi_to_place&gt;5 \n                                & acw.dist$pop.y&gt;4000]))\n# = 20\n\nSo there are 20 places that seemingly violate the ACW rule. One example is Oak Grove city of KY (pop 7,064) and Clarksville city of TN (pop 103,455) that are 7.64 miles apart. Another is Two Rivers city of WI (pop 12,639) and Manitowoc city also of WI (pop 34,053) that are 6.34 miles apart. Ultimately, there are 82 places that have population above 4000 and between (1,20) miles based on NBER."
  },
  {
    "objectID": "posts/2023-09-17-isolated-places/index.html#taking-a-stab-at-isolated-towns",
    "href": "posts/2023-09-17-isolated-places/index.html#taking-a-stab-at-isolated-towns",
    "title": "Isolated Places",
    "section": "Taking a stab at isolated towns",
    "text": "Taking a stab at isolated towns\nThe following code uses the first three rules to create a list of towns.\n\nclw.df &lt;- place.00.df %&gt;%\n  ungroup() %&gt;%\n  filter(pop.x&gt;=4000) %&gt;%\n  mutate(issue = pop.y&gt;=4000 & mi_to_place&lt;=20) %&gt;%\n  group_by(place1) %&gt;%\n  mutate(issues = sum(issue,na.rm = T),\n         num.around = sum(mi_to_place&lt;=20,na.rm=T),\n         pop.around = sum(pop.y*(mi_to_place&lt;=20),na.rm = T)) %&gt;%\n  filter(issues==0) %&gt;%\n  arrange(mi_to_place) %&gt;%\n  filter(row_number()==1)\n\nlength(clw.df$place1)\n# =541\nlength(unique(clw.df$place1[!(clw.df$place1 %in% unique(acw.df$placefip) )]))\n# =174 places in CLW list that are not in the ACW list\nlength(unique(clw.df$place1[(clw.df$place1 %in% unique(acw.df$placefip) )]))\n# =367 places in both CLW list and ACW list\n\n# Pop Around\nsummary(clw.df$num.around)\n#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#  0.000   3.000   7.000   8.072  12.000  32.000 \nsummary(clw.df$pop.around)\n# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#    0    2338    5832    6597    9160   29508 \n# \nlength(clw.df$place1[clw.df$pop.around&gt;10000])\n# =112\nlength(clw.df$place1[clw.df$pop.around&lt;5000])\n# =243\n\nBut one thing that I noticed is that many of these towns still have many neighbors and high surrounding populations even if no place has a large population. The mean population within 20 miles of an isolated town is about 6,600 people and the median is about 5,800. There are 112 towns with over 10,000 around them () There are only 243 isolated towns using the three rules with a surrounding population less than 5,000. This issue is also present in the ACW data."
  },
  {
    "objectID": "posts/2023-09-17-isolated-places/index.html#using-all-four-rules-to-make-isolated-towns",
    "href": "posts/2023-09-17-isolated-places/index.html#using-all-four-rules-to-make-isolated-towns",
    "title": "Isolated Places",
    "section": "Using all four rules to make isolated towns",
    "text": "Using all four rules to make isolated towns\nI am going to interpret rule 4 (again, this is if the centroid is within X miles then the same town) to include any place no matter the population (whereas, I expect that ACW meant it only for those places with over 4,000 population), I am going to do this in a network way (so that if A is close to B and B is close to C, then {A,B,C} are in a group together), and I am going to use 2 miles rather than 1 mile as in ACW. I am going to find groups by using the igraph package.\n\nlibrary(igraph)\n\n# isolate the places that are very close -- 2miles\nv.close.places &lt;- place.00.df %&gt;%\n  filter(mi_to_place&lt;2) %&gt;%\n  select(place1,place2)\n# using the igraph package, find the network of places\nv.close.places.graph &lt;- graph.data.frame(v.close.places)\n# manipulate to get the places in a data.frame\nv.close.members &lt;- data.frame(place.groups = clusters(v.close.places.graph)$membership)\nv.close.members$place &lt;- str_pad(row.names(v.close.members),width=7,pad=\"0\")\n\n# join with the place data, we are going to use the place in the network that has the highest population\nv.close.members &lt;- v.close.members %&gt;%\n  left_join(place.00.dat[,c(\"place.fip\",\"pop\")], by=c(\"place\"=\"place.fip\")) \n# create the data.frame we will merge into place.00.df\nv.close.members &lt;- v.close.members %&gt;%\n  group_by(place.groups) %&gt;%\n  filter(pop==max(pop)) %&gt;%\n  select(-pop) %&gt;%\n  rename(rep.place=place) %&gt;%\n  full_join(v.close.members) %&gt;%\n  ungroup() %&gt;%\n  group_by(place.groups) %&gt;%\n  mutate(pop.z = sum(pop)) %&gt;%\n  select(-pop)\n# clean up \nrm(v.close.places,v.close.places.graph)\ngc()\n\n# create dataset of places where the very close ones are merged together\n# remove if place1=place2\n# keep the places with minimum distance (conservative method)\nv.place.00.df &lt;-   place.00.df %&gt;%\n  left_join(v.close.members, by=c(\"place1\"=\"place\")) %&gt;%\n  left_join(v.close.members, by=c(\"place2\"=\"place\")) %&gt;%\n  mutate(place1 = if_else(is.na(rep.place.x),place1,rep.place.x)) %&gt;%\n  mutate(place2 = if_else(is.na(rep.place.y),place2,rep.place.y)) %&gt;%\n  mutate(tmp = place1==place2,\n         pop.x = if_else(tmp==T,pop.z.x,pop.x),\n         pop.y = if_else(tmp==T,pop.z.x,pop.y)\n         ) %&gt;%\n  ungroup() %&gt;%\n  group_by(place1,place2) %&gt;%\n  filter(mi_to_place==min(mi_to_place)) %&gt;%\n  ungroup() %&gt;%\n  filter(tmp==F) %&gt;%\n  select(place1,pop.x,place.nm.x,mi_to_place,place2,pop.y,place.nm.y)\n\n# use the same code as before to get the isolated towns\nv.clw.df &lt;- v.place.00.df %&gt;%\n  ungroup() %&gt;%\n  filter(pop.x&gt;=4000) %&gt;%\n  mutate(issue = pop.y&gt;=4000 & mi_to_place&lt;=20) %&gt;%\n  group_by(place1) %&gt;%\n  mutate(issues = sum(issue,na.rm = T),\n         num.around = sum((mi_to_place&lt;=20),na.rm=T),\n         pop.around = sum(pop.y*(mi_to_place&lt;=20),na.rm=T)) %&gt;%\n  filter(issues==0) %&gt;%\n  arrange(mi_to_place) %&gt;%\n  filter(row_number()==1) %&gt;%\n  select(-c(issue,issues))\n\nlength(v.clw.df$place1)\n# =651\nlength(v.clw.df$place1[!(v.clw.df$place1 %in% clw.df$place1)])\n# 112\nlength(v.clw.df$place1[(v.clw.df$place1 %in% clw.df$place1)])\n# 539\nlength(clw.df$place1[!(clw.df$place1 %in% v.clw.df$place1)])\n# 2\nsummary(v.clw.df$num.around)\n#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#  0.000   3.000   6.000   7.329  11.000  34.000 \nsummary(v.clw.df$pop.around)\n#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#      0    2100    5126    6221    8785   31483 \nlength(v.clw.df$place1[v.clw.df$pop.around&gt;10000])\n# =122\nlength(v.clw.df$place1[v.clw.df$pop.around&lt;5000])\n# =316\n\nThis increases the number of isolated towns because there are small close places that end up being added together to get above 4,000 population. There are 112 places that are in v.clw.df but not clw.df and two in clw.df but not in v.clw.df. The mean and median population around a town has gone down, likely because some have been absorbed into the new combined place. Finally, there are again 112 places that have surrounding populations over 10,000."
  },
  {
    "objectID": "posts/2023-09-17-isolated-places/index.html#conclusion",
    "href": "posts/2023-09-17-isolated-places/index.html#conclusion",
    "title": "Isolated Places",
    "section": "Conclusion",
    "text": "Conclusion\nI have pointed out some data sources, looked at the ACW data, and tried to come up with two alternative lists. ACW also connects the towns with zipcodes, which helps when combining with the ZBP, which I have not done."
  },
  {
    "objectID": "posts/2022-07-31-something-new/index.html",
    "href": "posts/2022-07-31-something-new/index.html",
    "title": "A New Website",
    "section": "",
    "text": "I saw a couple of websites and thought mine could do with an update. In particular, Andrew Heiss has an amazing website… but I don’t know how to replicate it. Thus, I am borrowing from Mike Mahoney before he creates something too advanced for me to follow."
  },
  {
    "objectID": "posts/2022-07-31-something-new/index.html#how-did-i-do-it",
    "href": "posts/2022-07-31-something-new/index.html#how-did-i-do-it",
    "title": "A New Website",
    "section": "How did I do it",
    "text": "How did I do it\n\nTools\n\nI used Rstudio + quarto, which I learned about through Andrew Heiss’s twitter.\nI saw Mike Mahoney’s website in the quarto gallery\nI already had Github account and the desktop app\n\n\n\nSteps\n\nI downloaded Mike Mahoney’s website\nI changed all the content to match what I wanted\nI used the Quarto guide on Github Pages, but I also had to google a bit to figure out some stuff\n\nName the folder with the website content something (e.g., tmp_website)\nOn Github, new repository named “username.github.io”, initialize with a readme file, then “create”\nOn code-tab, create new branch called “gh-pages”, next, in same tab, click “2 branches”, next switch branch to “gh-pages” from “main”, and then delete “main”\nCreate “username.github.io” folder, paste website contents into the folder\nAdd the “Ignore Content” item to the .gitignore folder (will likely need to use ‘open with’ and pick a program)\nUsing the Github desktop app, sync the new items to Github website\nIn terminal (or command line), cd to username.github.io, next type quarto publish gh-pages and hit enter, and say yes to any questions\n\nThe website should go live within a few minutes (as long as not uploading big data files)"
  },
  {
    "objectID": "posts/2018-06-18-tfp-guide/index.html",
    "href": "posts/2018-06-18-tfp-guide/index.html",
    "title": "TFP Guide",
    "section": "",
    "text": "These are notes I wrote on Total Factor Productivity (TFP) and production function estimation as a research assistant: TFP_guide.pdf. These notes are a mix of theory and code to estimate. I should liberate the code from the pdf. I think there is now a Stata or R package that does several different methods."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "C. Luke Watson",
    "section": "",
    "text": "I am a Senior Financial Economist in the Center for Financial Research at the Federal Deposit Insurance Corporation. For the FDIC, I research bank branching decisions, consumer access to banking services, and the emergence of online banking. In addition, my corporate work includes methodological and performance evaluation of bank financial models as part of the Quantitative Risk Analysis section. My dissertation work focused on the general equilibrium effects of the Earned Income Tax Credit and market power in urban rental markets.\nI earned my PhD in economics from Michigan State University’s College of Social Science in 2021. I earned my BA and MA in economics for Old Dominion University’s Strome College of Business. I am from Portsmouth, VA, and I am currently living in Alexandria, VA.\nOn this site, I maintain my CV and research materials, as well as a blog.\nThe views and opinions expressed on this website do not reflect those of the FDIC, the United States, nor anyone else."
  },
  {
    "objectID": "index.html#howdy-world",
    "href": "index.html#howdy-world",
    "title": "C. Luke Watson",
    "section": "",
    "text": "I am a Senior Financial Economist in the Center for Financial Research at the Federal Deposit Insurance Corporation. For the FDIC, I research bank branching decisions, consumer access to banking services, and the emergence of online banking. In addition, my corporate work includes methodological and performance evaluation of bank financial models as part of the Quantitative Risk Analysis section. My dissertation work focused on the general equilibrium effects of the Earned Income Tax Credit and market power in urban rental markets.\nI earned my PhD in economics from Michigan State University’s College of Social Science in 2021. I earned my BA and MA in economics for Old Dominion University’s Strome College of Business. I am from Portsmouth, VA, and I am currently living in Alexandria, VA.\nOn this site, I maintain my CV and research materials, as well as a blog.\nThe views and opinions expressed on this website do not reflect those of the FDIC, the United States, nor anyone else."
  },
  {
    "objectID": "people/index.html",
    "href": "people/index.html",
    "title": "People I Know",
    "section": "",
    "text": "I know people who do interesting things. Here are some of them:"
  },
  {
    "objectID": "people/index.html#advisors",
    "href": "people/index.html#advisors",
    "title": "People I Know",
    "section": "Advisors",
    "text": "Advisors\n\nMSU\n\nOren Ziv: trade, urban\nJay Wilson: public, trade, urban\n\nODU\n\nGary Wagner: public, state & local, regional – now at U. Louisiana\nTim Komarek: urban and regional, public, and resource"
  },
  {
    "objectID": "people/index.html#grad-school-friends",
    "href": "people/index.html#grad-school-friends",
    "title": "People I Know",
    "section": "Grad School friends",
    "text": "Grad School friends\n\nRiley Acton: labor, education\nChristian Cox: public, political economy, io\nHannah Gabriel: macro, international\nAkanksha Negi: econometrics\nCody Orr: labor, education\nGabrielle Pepin: public\nNick Rowe: macro, trade\nRuonan Xu: econometrics\nDylan Brewer: environmental, io"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "C. Luke Watson",
    "section": "",
    "text": "A personal blog for data projects as well as my goings-on.\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nIsolated Places\n\n\n\n\n\n\n\nStructural IO\n\n\nUrban\n\n\nEntry Model\n\n\nData\n\n\n\n\nIsolating Isolated Places\n\n\n\n\n\n\nSep 17, 2023\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nA New Website\n\n\n\n\n\n\n\nWebsite\n\n\nQuarto\n\n\nTutorials\n\n\nGithub\n\n\n\n\nTrying something new\n\n\n\n\n\n\nJul 31, 2022\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nFirst year notes on preference relations\n\n\n\n\n\n\n\nNotes\n\n\nPreferences\n\n\nPHD Micro\n\n\n\n\nFirst year notes on preference relations\n\n\n\n\n\n\nJun 9, 2020\n\n\nC. Luke Watson\n\n\n\n\n\n\n  \n\n\n\n\nTFP Guide\n\n\n\n\n\n\n\nNotes\n\n\nTFP\n\n\nProduction Function Estimation\n\n\n\n\nA TFP guide I made\n\n\n\n\n\n\nJun 18, 2018\n\n\nC. Luke Watson\n\n\n\n\n\n\nNo matching items"
  }
]